{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "G_ujFC0JO1rC"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "WHKN5agZPReO"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs=4\n",
        "batch_size=4\n",
        "lr=0.001"
      ],
      "metadata": {
        "id": "S-Lr2GD2PewF"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform=transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))\n",
        "])"
      ],
      "metadata": {
        "id": "NCp6EigjPest"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset=torchvision.datasets.CIFAR10(root='./data',train=True,download=True,transform=transform)\n",
        "test_dataset=torchvision.datasets.CIFAR10(root='./data',train=False,download=True,transform=transform)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dlesu-nfPeqE",
        "outputId": "1e1b9ff3-427d-47d5-8802-2aafc992a109"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainloader=torch.utils.data.DataLoader(train_dataset,batch_size=batch_size,shuffle=True)\n",
        "testloader=torch.utils.data.DataLoader(test_dataset,batch_size=batch_size,shuffle=False)"
      ],
      "metadata": {
        "id": "4uxQoioaPena"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "firstdata=iter(trainloader)\n",
        "features,labels=next(firstdata)\n",
        "print(features.shape,labels.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BJi2NrFhPek7",
        "outputId": "3ff383ab-0dc0-4c42-c98c-a7d313b860a6"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 3, 32, 32]) torch.Size([4])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classes=('plane','car','bird','cat','deer','dog','frog','horse','ship','truck')"
      ],
      "metadata": {
        "id": "9LU9mueMRfWT"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ConvNet(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(ConvNet,self).__init__()\n",
        "    self.conv1=nn.Conv2d(3,6,5)\n",
        "    self.pool=nn.MaxPool2d(2,2)\n",
        "    self.conv2=nn.Conv2d(6,16,5)\n",
        "    self.fc1=nn.Linear(16*5*5,120)\n",
        "    self.fc2=nn.Linear(120,84)\n",
        "    self.fc3=nn.Linear(84,10)\n",
        "\n",
        "\n",
        "  def forward(self,x):\n",
        "    x=self.pool(F.relu(self.conv1(x)))\n",
        "    x=self.pool(F.relu(self.conv2(x)))\n",
        "    x=x.view(-1,16*5*5)\n",
        "    x=F.relu(self.fc1(x))\n",
        "    x=F.relu(self.fc2(x))\n",
        "    x=self.fc3(x)\n",
        "    return x\n",
        "\n"
      ],
      "metadata": {
        "id": "DmIrqfZgR3_5"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model=ConvNet().to(device)"
      ],
      "metadata": {
        "id": "U6T6qLeZSEkS"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion=nn.CrossEntropyLoss()\n",
        "optimizer=torch.optim.SGD(model.parameters(),lr=lr)\n"
      ],
      "metadata": {
        "id": "aj42arf5SL0C"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_total_steps=len(trainloader)\n",
        "for epoch in range(num_epochs):\n",
        "  for i,(images,labels) in enumerate(trainloader):\n",
        "    images=images.to(device)\n",
        "    labels=labels.to(device)\n",
        "\n",
        "\n",
        "    outputs=model(images)\n",
        "    loss=criterion(outputs,labels)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if (i+1)%200==0:\n",
        "      print(f'Epoch: {epoch}/{num_epochs}   step: {i+1}/{n_total_steps}  loss: {loss.item():.3f} ')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YpofOMetTkEO",
        "outputId": "fb5b70bf-a38b-405d-beeb-a05d00e61ec5"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0/4   step: 200/12500  loss: 2.322 \n",
            "Epoch: 0/4   step: 400/12500  loss: 2.276 \n",
            "Epoch: 0/4   step: 600/12500  loss: 2.319 \n",
            "Epoch: 0/4   step: 800/12500  loss: 2.302 \n",
            "Epoch: 0/4   step: 1000/12500  loss: 2.336 \n",
            "Epoch: 0/4   step: 1200/12500  loss: 2.301 \n",
            "Epoch: 0/4   step: 1400/12500  loss: 2.318 \n",
            "Epoch: 0/4   step: 1600/12500  loss: 2.314 \n",
            "Epoch: 0/4   step: 1800/12500  loss: 2.290 \n",
            "Epoch: 0/4   step: 2000/12500  loss: 2.287 \n",
            "Epoch: 0/4   step: 2200/12500  loss: 2.289 \n",
            "Epoch: 0/4   step: 2400/12500  loss: 2.279 \n",
            "Epoch: 0/4   step: 2600/12500  loss: 2.288 \n",
            "Epoch: 0/4   step: 2800/12500  loss: 2.310 \n",
            "Epoch: 0/4   step: 3000/12500  loss: 2.293 \n",
            "Epoch: 0/4   step: 3200/12500  loss: 2.291 \n",
            "Epoch: 0/4   step: 3400/12500  loss: 2.321 \n",
            "Epoch: 0/4   step: 3600/12500  loss: 2.334 \n",
            "Epoch: 0/4   step: 3800/12500  loss: 2.296 \n",
            "Epoch: 0/4   step: 4000/12500  loss: 2.321 \n",
            "Epoch: 0/4   step: 4200/12500  loss: 2.286 \n",
            "Epoch: 0/4   step: 4400/12500  loss: 2.284 \n",
            "Epoch: 0/4   step: 4600/12500  loss: 2.312 \n",
            "Epoch: 0/4   step: 4800/12500  loss: 2.298 \n",
            "Epoch: 0/4   step: 5000/12500  loss: 2.300 \n",
            "Epoch: 0/4   step: 5200/12500  loss: 2.283 \n",
            "Epoch: 0/4   step: 5400/12500  loss: 2.283 \n",
            "Epoch: 0/4   step: 5600/12500  loss: 2.283 \n",
            "Epoch: 0/4   step: 5800/12500  loss: 2.286 \n",
            "Epoch: 0/4   step: 6000/12500  loss: 2.299 \n",
            "Epoch: 0/4   step: 6200/12500  loss: 2.221 \n",
            "Epoch: 0/4   step: 6400/12500  loss: 2.283 \n",
            "Epoch: 0/4   step: 6600/12500  loss: 2.304 \n",
            "Epoch: 0/4   step: 6800/12500  loss: 2.347 \n",
            "Epoch: 0/4   step: 7000/12500  loss: 2.293 \n",
            "Epoch: 0/4   step: 7200/12500  loss: 2.341 \n",
            "Epoch: 0/4   step: 7400/12500  loss: 2.296 \n",
            "Epoch: 0/4   step: 7600/12500  loss: 2.255 \n",
            "Epoch: 0/4   step: 7800/12500  loss: 2.235 \n",
            "Epoch: 0/4   step: 8000/12500  loss: 2.235 \n",
            "Epoch: 0/4   step: 8200/12500  loss: 2.316 \n",
            "Epoch: 0/4   step: 8400/12500  loss: 2.324 \n",
            "Epoch: 0/4   step: 8600/12500  loss: 2.203 \n",
            "Epoch: 0/4   step: 8800/12500  loss: 2.174 \n",
            "Epoch: 0/4   step: 9000/12500  loss: 2.232 \n",
            "Epoch: 0/4   step: 9200/12500  loss: 2.249 \n",
            "Epoch: 0/4   step: 9400/12500  loss: 2.282 \n",
            "Epoch: 0/4   step: 9600/12500  loss: 2.229 \n",
            "Epoch: 0/4   step: 9800/12500  loss: 2.350 \n",
            "Epoch: 0/4   step: 10000/12500  loss: 2.504 \n",
            "Epoch: 0/4   step: 10200/12500  loss: 2.292 \n",
            "Epoch: 0/4   step: 10400/12500  loss: 2.316 \n",
            "Epoch: 0/4   step: 10600/12500  loss: 2.246 \n",
            "Epoch: 0/4   step: 10800/12500  loss: 2.110 \n",
            "Epoch: 0/4   step: 11000/12500  loss: 2.190 \n",
            "Epoch: 0/4   step: 11200/12500  loss: 2.423 \n",
            "Epoch: 0/4   step: 11400/12500  loss: 2.149 \n",
            "Epoch: 0/4   step: 11600/12500  loss: 2.031 \n",
            "Epoch: 0/4   step: 11800/12500  loss: 1.832 \n",
            "Epoch: 0/4   step: 12000/12500  loss: 2.017 \n",
            "Epoch: 0/4   step: 12200/12500  loss: 2.139 \n",
            "Epoch: 0/4   step: 12400/12500  loss: 2.041 \n",
            "Epoch: 1/4   step: 200/12500  loss: 3.247 \n",
            "Epoch: 1/4   step: 400/12500  loss: 1.821 \n",
            "Epoch: 1/4   step: 600/12500  loss: 2.450 \n",
            "Epoch: 1/4   step: 800/12500  loss: 2.030 \n",
            "Epoch: 1/4   step: 1000/12500  loss: 2.342 \n",
            "Epoch: 1/4   step: 1200/12500  loss: 2.044 \n",
            "Epoch: 1/4   step: 1400/12500  loss: 2.211 \n",
            "Epoch: 1/4   step: 1600/12500  loss: 2.289 \n",
            "Epoch: 1/4   step: 1800/12500  loss: 1.976 \n",
            "Epoch: 1/4   step: 2000/12500  loss: 1.974 \n",
            "Epoch: 1/4   step: 2200/12500  loss: 2.475 \n",
            "Epoch: 1/4   step: 2400/12500  loss: 2.251 \n",
            "Epoch: 1/4   step: 2600/12500  loss: 2.795 \n",
            "Epoch: 1/4   step: 2800/12500  loss: 2.296 \n",
            "Epoch: 1/4   step: 3000/12500  loss: 2.667 \n",
            "Epoch: 1/4   step: 3200/12500  loss: 1.939 \n",
            "Epoch: 1/4   step: 3400/12500  loss: 1.715 \n",
            "Epoch: 1/4   step: 3600/12500  loss: 2.041 \n",
            "Epoch: 1/4   step: 3800/12500  loss: 2.209 \n",
            "Epoch: 1/4   step: 4000/12500  loss: 1.984 \n",
            "Epoch: 1/4   step: 4200/12500  loss: 2.217 \n",
            "Epoch: 1/4   step: 4400/12500  loss: 1.759 \n",
            "Epoch: 1/4   step: 4600/12500  loss: 1.895 \n",
            "Epoch: 1/4   step: 4800/12500  loss: 2.143 \n",
            "Epoch: 1/4   step: 5000/12500  loss: 1.798 \n",
            "Epoch: 1/4   step: 5200/12500  loss: 1.948 \n",
            "Epoch: 1/4   step: 5400/12500  loss: 1.690 \n",
            "Epoch: 1/4   step: 5600/12500  loss: 1.438 \n",
            "Epoch: 1/4   step: 5800/12500  loss: 2.055 \n",
            "Epoch: 1/4   step: 6000/12500  loss: 1.963 \n",
            "Epoch: 1/4   step: 6200/12500  loss: 1.612 \n",
            "Epoch: 1/4   step: 6400/12500  loss: 2.060 \n",
            "Epoch: 1/4   step: 6600/12500  loss: 1.691 \n",
            "Epoch: 1/4   step: 6800/12500  loss: 2.052 \n",
            "Epoch: 1/4   step: 7000/12500  loss: 1.770 \n",
            "Epoch: 1/4   step: 7200/12500  loss: 2.086 \n",
            "Epoch: 1/4   step: 7400/12500  loss: 2.588 \n",
            "Epoch: 1/4   step: 7600/12500  loss: 1.645 \n",
            "Epoch: 1/4   step: 7800/12500  loss: 1.915 \n",
            "Epoch: 1/4   step: 8000/12500  loss: 2.214 \n",
            "Epoch: 1/4   step: 8200/12500  loss: 1.866 \n",
            "Epoch: 1/4   step: 8400/12500  loss: 1.253 \n",
            "Epoch: 1/4   step: 8600/12500  loss: 1.792 \n",
            "Epoch: 1/4   step: 8800/12500  loss: 2.366 \n",
            "Epoch: 1/4   step: 9000/12500  loss: 2.512 \n",
            "Epoch: 1/4   step: 9200/12500  loss: 2.088 \n",
            "Epoch: 1/4   step: 9400/12500  loss: 2.120 \n",
            "Epoch: 1/4   step: 9600/12500  loss: 1.709 \n",
            "Epoch: 1/4   step: 9800/12500  loss: 2.495 \n",
            "Epoch: 1/4   step: 10000/12500  loss: 2.445 \n",
            "Epoch: 1/4   step: 10200/12500  loss: 1.839 \n",
            "Epoch: 1/4   step: 10400/12500  loss: 1.870 \n",
            "Epoch: 1/4   step: 10600/12500  loss: 2.577 \n",
            "Epoch: 1/4   step: 10800/12500  loss: 2.203 \n",
            "Epoch: 1/4   step: 11000/12500  loss: 2.227 \n",
            "Epoch: 1/4   step: 11200/12500  loss: 2.040 \n",
            "Epoch: 1/4   step: 11400/12500  loss: 1.792 \n",
            "Epoch: 1/4   step: 11600/12500  loss: 1.724 \n",
            "Epoch: 1/4   step: 11800/12500  loss: 1.677 \n",
            "Epoch: 1/4   step: 12000/12500  loss: 1.424 \n",
            "Epoch: 1/4   step: 12200/12500  loss: 2.405 \n",
            "Epoch: 1/4   step: 12400/12500  loss: 1.083 \n",
            "Epoch: 2/4   step: 200/12500  loss: 2.053 \n",
            "Epoch: 2/4   step: 400/12500  loss: 2.066 \n",
            "Epoch: 2/4   step: 600/12500  loss: 1.692 \n",
            "Epoch: 2/4   step: 800/12500  loss: 1.557 \n",
            "Epoch: 2/4   step: 1000/12500  loss: 1.400 \n",
            "Epoch: 2/4   step: 1200/12500  loss: 1.351 \n",
            "Epoch: 2/4   step: 1400/12500  loss: 1.875 \n",
            "Epoch: 2/4   step: 1600/12500  loss: 1.300 \n",
            "Epoch: 2/4   step: 1800/12500  loss: 1.957 \n",
            "Epoch: 2/4   step: 2000/12500  loss: 2.614 \n",
            "Epoch: 2/4   step: 2200/12500  loss: 2.079 \n",
            "Epoch: 2/4   step: 2400/12500  loss: 1.509 \n",
            "Epoch: 2/4   step: 2600/12500  loss: 2.189 \n",
            "Epoch: 2/4   step: 2800/12500  loss: 1.890 \n",
            "Epoch: 2/4   step: 3000/12500  loss: 2.164 \n",
            "Epoch: 2/4   step: 3200/12500  loss: 1.716 \n",
            "Epoch: 2/4   step: 3400/12500  loss: 2.199 \n",
            "Epoch: 2/4   step: 3600/12500  loss: 2.032 \n",
            "Epoch: 2/4   step: 3800/12500  loss: 1.194 \n",
            "Epoch: 2/4   step: 4000/12500  loss: 1.321 \n",
            "Epoch: 2/4   step: 4200/12500  loss: 1.909 \n",
            "Epoch: 2/4   step: 4400/12500  loss: 1.801 \n",
            "Epoch: 2/4   step: 4600/12500  loss: 1.363 \n",
            "Epoch: 2/4   step: 4800/12500  loss: 1.685 \n",
            "Epoch: 2/4   step: 5000/12500  loss: 1.969 \n",
            "Epoch: 2/4   step: 5200/12500  loss: 1.798 \n",
            "Epoch: 2/4   step: 5400/12500  loss: 1.719 \n",
            "Epoch: 2/4   step: 5600/12500  loss: 1.996 \n",
            "Epoch: 2/4   step: 5800/12500  loss: 1.405 \n",
            "Epoch: 2/4   step: 6000/12500  loss: 1.909 \n",
            "Epoch: 2/4   step: 6200/12500  loss: 2.417 \n",
            "Epoch: 2/4   step: 6400/12500  loss: 1.442 \n",
            "Epoch: 2/4   step: 6600/12500  loss: 1.486 \n",
            "Epoch: 2/4   step: 6800/12500  loss: 2.226 \n",
            "Epoch: 2/4   step: 7000/12500  loss: 1.432 \n",
            "Epoch: 2/4   step: 7200/12500  loss: 1.117 \n",
            "Epoch: 2/4   step: 7400/12500  loss: 1.618 \n",
            "Epoch: 2/4   step: 7600/12500  loss: 1.322 \n",
            "Epoch: 2/4   step: 7800/12500  loss: 0.809 \n",
            "Epoch: 2/4   step: 8000/12500  loss: 1.413 \n",
            "Epoch: 2/4   step: 8200/12500  loss: 1.230 \n",
            "Epoch: 2/4   step: 8400/12500  loss: 2.647 \n",
            "Epoch: 2/4   step: 8600/12500  loss: 1.092 \n",
            "Epoch: 2/4   step: 8800/12500  loss: 2.362 \n",
            "Epoch: 2/4   step: 9000/12500  loss: 2.059 \n",
            "Epoch: 2/4   step: 9200/12500  loss: 2.317 \n",
            "Epoch: 2/4   step: 9400/12500  loss: 1.715 \n",
            "Epoch: 2/4   step: 9600/12500  loss: 1.503 \n",
            "Epoch: 2/4   step: 9800/12500  loss: 1.563 \n",
            "Epoch: 2/4   step: 10000/12500  loss: 1.815 \n",
            "Epoch: 2/4   step: 10200/12500  loss: 1.525 \n",
            "Epoch: 2/4   step: 10400/12500  loss: 1.648 \n",
            "Epoch: 2/4   step: 10600/12500  loss: 2.209 \n",
            "Epoch: 2/4   step: 10800/12500  loss: 1.332 \n",
            "Epoch: 2/4   step: 11000/12500  loss: 0.716 \n",
            "Epoch: 2/4   step: 11200/12500  loss: 1.367 \n",
            "Epoch: 2/4   step: 11400/12500  loss: 1.252 \n",
            "Epoch: 2/4   step: 11600/12500  loss: 1.655 \n",
            "Epoch: 2/4   step: 11800/12500  loss: 1.772 \n",
            "Epoch: 2/4   step: 12000/12500  loss: 1.318 \n",
            "Epoch: 2/4   step: 12200/12500  loss: 1.739 \n",
            "Epoch: 2/4   step: 12400/12500  loss: 2.127 \n",
            "Epoch: 3/4   step: 200/12500  loss: 1.362 \n",
            "Epoch: 3/4   step: 400/12500  loss: 1.368 \n",
            "Epoch: 3/4   step: 600/12500  loss: 1.605 \n",
            "Epoch: 3/4   step: 800/12500  loss: 1.565 \n",
            "Epoch: 3/4   step: 1000/12500  loss: 2.089 \n",
            "Epoch: 3/4   step: 1200/12500  loss: 1.237 \n",
            "Epoch: 3/4   step: 1400/12500  loss: 1.293 \n",
            "Epoch: 3/4   step: 1600/12500  loss: 2.270 \n",
            "Epoch: 3/4   step: 1800/12500  loss: 2.317 \n",
            "Epoch: 3/4   step: 2000/12500  loss: 2.128 \n",
            "Epoch: 3/4   step: 2200/12500  loss: 1.990 \n",
            "Epoch: 3/4   step: 2400/12500  loss: 1.133 \n",
            "Epoch: 3/4   step: 2600/12500  loss: 1.446 \n",
            "Epoch: 3/4   step: 2800/12500  loss: 1.422 \n",
            "Epoch: 3/4   step: 3000/12500  loss: 2.746 \n",
            "Epoch: 3/4   step: 3200/12500  loss: 1.572 \n",
            "Epoch: 3/4   step: 3400/12500  loss: 1.670 \n",
            "Epoch: 3/4   step: 3600/12500  loss: 1.193 \n",
            "Epoch: 3/4   step: 3800/12500  loss: 1.721 \n",
            "Epoch: 3/4   step: 4000/12500  loss: 1.246 \n",
            "Epoch: 3/4   step: 4200/12500  loss: 1.045 \n",
            "Epoch: 3/4   step: 4400/12500  loss: 1.909 \n",
            "Epoch: 3/4   step: 4600/12500  loss: 1.515 \n",
            "Epoch: 3/4   step: 4800/12500  loss: 1.771 \n",
            "Epoch: 3/4   step: 5000/12500  loss: 2.200 \n",
            "Epoch: 3/4   step: 5200/12500  loss: 1.035 \n",
            "Epoch: 3/4   step: 5400/12500  loss: 1.188 \n",
            "Epoch: 3/4   step: 5600/12500  loss: 1.943 \n",
            "Epoch: 3/4   step: 5800/12500  loss: 1.192 \n",
            "Epoch: 3/4   step: 6000/12500  loss: 1.978 \n",
            "Epoch: 3/4   step: 6200/12500  loss: 1.376 \n",
            "Epoch: 3/4   step: 6400/12500  loss: 0.959 \n",
            "Epoch: 3/4   step: 6600/12500  loss: 1.550 \n",
            "Epoch: 3/4   step: 6800/12500  loss: 2.476 \n",
            "Epoch: 3/4   step: 7000/12500  loss: 1.168 \n",
            "Epoch: 3/4   step: 7200/12500  loss: 1.278 \n",
            "Epoch: 3/4   step: 7400/12500  loss: 1.813 \n",
            "Epoch: 3/4   step: 7600/12500  loss: 1.254 \n",
            "Epoch: 3/4   step: 7800/12500  loss: 0.720 \n",
            "Epoch: 3/4   step: 8000/12500  loss: 1.310 \n",
            "Epoch: 3/4   step: 8200/12500  loss: 0.858 \n",
            "Epoch: 3/4   step: 8400/12500  loss: 0.749 \n",
            "Epoch: 3/4   step: 8600/12500  loss: 1.815 \n",
            "Epoch: 3/4   step: 8800/12500  loss: 1.976 \n",
            "Epoch: 3/4   step: 9000/12500  loss: 1.060 \n",
            "Epoch: 3/4   step: 9200/12500  loss: 1.460 \n",
            "Epoch: 3/4   step: 9400/12500  loss: 1.896 \n",
            "Epoch: 3/4   step: 9600/12500  loss: 1.444 \n",
            "Epoch: 3/4   step: 9800/12500  loss: 1.208 \n",
            "Epoch: 3/4   step: 10000/12500  loss: 0.638 \n",
            "Epoch: 3/4   step: 10200/12500  loss: 1.405 \n",
            "Epoch: 3/4   step: 10400/12500  loss: 1.461 \n",
            "Epoch: 3/4   step: 10600/12500  loss: 1.475 \n",
            "Epoch: 3/4   step: 10800/12500  loss: 1.231 \n",
            "Epoch: 3/4   step: 11000/12500  loss: 2.132 \n",
            "Epoch: 3/4   step: 11200/12500  loss: 1.231 \n",
            "Epoch: 3/4   step: 11400/12500  loss: 3.139 \n",
            "Epoch: 3/4   step: 11600/12500  loss: 1.200 \n",
            "Epoch: 3/4   step: 11800/12500  loss: 1.107 \n",
            "Epoch: 3/4   step: 12000/12500  loss: 1.470 \n",
            "Epoch: 3/4   step: 12200/12500  loss: 0.634 \n",
            "Epoch: 3/4   step: 12400/12500  loss: 1.053 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "    n_correct = 0\n",
        "    n_samples = 0\n",
        "    n_class_correct = [0 for _ in range(10)]\n",
        "    n_class_sample = [0 for _ in range(10)]\n",
        "\n",
        "    for images, labels in testloader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "        n_samples += labels.size(0)\n",
        "        n_correct += (predicted == labels).sum().item()\n",
        "\n",
        "        for i in range(labels.size(0)):\n",
        "            label = labels[i].item()\n",
        "            pred = predicted[i].item()\n",
        "\n",
        "\n",
        "            if 0 <= label < 10:\n",
        "                if label == pred:\n",
        "                    n_class_correct[label] += 1\n",
        "                n_class_sample[label] += 1\n",
        "            else:\n",
        "                print(f'Warning: Label {label} is out of range. Expected range: 0 to 9')\n",
        "\n",
        "    acc = 100.0 * n_correct / n_samples if n_samples > 0 else 0.0\n",
        "    print(f'Overall Accuracy: {acc:.2f}%')\n",
        "\n",
        "    for i in range(10):\n",
        "        if n_class_sample[i] > 0:\n",
        "            class_acc = 100 * n_class_correct[i] / n_class_sample[i]\n",
        "            print(f'Accuracy of {classes[i]}: {class_acc:.2f}%')\n",
        "        else:\n",
        "            print(f'Accuracy of {classes[i]}: N/A (no samples)')\n"
      ],
      "metadata": {
        "id": "OybXQacRbR9D",
        "outputId": "78100bc9-cc8d-4cca-d033-0f167182929b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overall Accuracy: 45.95%\n",
            "Accuracy of plane: 45.30%\n",
            "Accuracy of car: 57.60%\n",
            "Accuracy of bird: 37.50%\n",
            "Accuracy of cat: 28.10%\n",
            "Accuracy of deer: 27.30%\n",
            "Accuracy of dog: 29.00%\n",
            "Accuracy of frog: 55.70%\n",
            "Accuracy of horse: 57.90%\n",
            "Accuracy of ship: 66.50%\n",
            "Accuracy of truck: 54.60%\n"
          ]
        }
      ]
    }
  ]
}